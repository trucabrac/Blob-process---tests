{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image processing for timelapse blob images\n",
    "-> convert to grayscale, homogeneize light, maybe crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read image\n",
    "will have to be adapted for batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd images-originals/\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img_path = 'tl10-168.jpg'\n",
    "\n",
    "#if conversion to RGB (but not useful as we conv to gray)\n",
    "#BGR_img = cv2.imread(img_path)\n",
    "#orig_img = cv2.cvtColor(BGR_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "orig_img = cv2.imread(img_path)\n",
    "\n",
    "#img = mpimg.imread('tl10-168.jpg')\n",
    "plt.imshow(orig_img)\n",
    "#plt.imshow(img_b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion to grayscale\n",
    "img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropping if necessary\n",
    "crop_img = img[300:2500, 400:2300]\n",
    "plt.imshow(crop_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global adjustment of brightness and contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global adjustment of brightness and contrast\n",
    "#    alpha = float(input('* Enter the alpha value [1.0-3.0]: '))\n",
    "#    beta = int(input('* Enter the beta value [0-100]: '))\n",
    "alpha = 1   #contrast\n",
    "beta = 40   #brightness\n",
    "adj_img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "plt.imshow(adj_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion to grayscale\n",
    "parameters to adjust to darken yellow tones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# conversion to grayscale\n",
    "#https://amiradata.com/convert-an-image-to-grayscale-using-python/\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = adj_img\n",
    "\n",
    "# create figure\n",
    "fig = plt.figure(figsize=(20, 7))\n",
    "# setting values to rows and column variables\n",
    "rows = 1\n",
    "columns = 2\n",
    " \n",
    "B, G, R = img[:, :, 0], img[:, :, 1], img[:, :, 2]\n",
    "\n",
    "# standard values for grayscale conversion\n",
    "gray_img_st = 0.2989 * R + 0.587 * G + 0.014 * B\n",
    "# Adds a subplot at the 1st position\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "# showing image\n",
    "plt.imshow(gray_img_st, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"standard\")\n",
    "\n",
    "# weighted to darken yellow tones\n",
    "#gr_img = 0.0989 * R + 0.487 * G + 0.114 * B\n",
    "gr_img = 0.2989 * R + 0.587 * G + 0.914 * B\n",
    "# Adds a subplot at the 2nd position\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "# showing image\n",
    "plt.imshow(gr_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"Weighted\")\n",
    "#plt.imshow(gray_img, cmap='gray')\n",
    "#plt.show()\n",
    "\n",
    "cv2.imwrite(\"grayscale.jpg\", gr_img)\n",
    "fig.savefig('savefig_test.png', dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare methods to convert to grayscale\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = adj_img\n",
    "\n",
    "# create figure\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "# setting values to rows and column variables\n",
    "rows = 3\n",
    "columns = 2\n",
    "\n",
    "#method 1\n",
    "gr1_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(gr1_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"cv2.COLOR_BGR2GRAY\")\n",
    "#method 2\n",
    "from skimage import color \n",
    "gr2_img = color.rgb2gray(img)\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(gr2_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"scikit color.rgb2gray\")\n",
    "#method 3\n",
    "B, G, R = img[:, :, 0], img[:, :, 1], img[:, :, 2]\n",
    "gr3_img = 0.2989 * R + 0.587 * G + 0.114 * B\n",
    "fig.add_subplot(rows, columns, 3)\n",
    "plt.imshow(gr3_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"st equation\")\n",
    "#method 4\n",
    "# weighted to lighten blue tones\n",
    "B, G, R = img[:, :, 0], img[:, :, 1], img[:, :, 2]\n",
    "gr4_img = 0.2989 * R + 0.587 * G + 0.0114 * B\n",
    "fig.add_subplot(rows, columns, 4)\n",
    "plt.imshow(gr4_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"weighted equation - blue lighter\")\n",
    "#method 5\n",
    "# weighted to darken green tones + light blue tones\n",
    "B, G, R = img[:, :, 0], img[:, :, 1], img[:, :, 2]\n",
    "#gr_img = 0.0989 * R + 0.487 * G + 0.114 * B\n",
    "gr5_img = 0.0989 * R + 0.487 * G + 0.114 * B\n",
    "fig.add_subplot(rows, columns, 5)\n",
    "plt.imshow(gr5_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"weighted equation - green darker + blue lighter\")\n",
    "#method 6\n",
    "gr6_img[:] = np.max(img,axis=-1,keepdims=1)/2 + np.min(img,axis=-1,keepdims=1)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more advanced calc https://muthu.co/converting-color-images-to-grayscale-using-numpy-and-some-mathematics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare methods to convert to grayscale\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = orig_img\n",
    "\n",
    "# create figure\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "# setting values to rows and column variables\n",
    "rows = 3\n",
    "columns = 2\n",
    "\n",
    "#method 1\n",
    "gr1_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(gr1_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"cv2.COLOR_BGR2GRAY\")\n",
    "#method 2\n",
    "from skimage import color \n",
    "#luminosity_constant = [0.21,0.72,0.07] # standard\n",
    "luminosity_constant = [0.07,0.82,0.31]\n",
    "gr2_img = np.dot(orig_img[...,:3], luminosity_constant).astype(np.uint8)\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(gr2_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"luminosity weighted standard\")\n",
    "#cv2.imwrite(\"gray_lumi.jpg\", gr2_img)\n",
    "#method 3\n",
    "B, G, R = img[:, :, 0], img[:, :, 1], img[:, :, 2]\n",
    "gr3_img = 0.2989 * R + 0.587 * G + 0.114 * B\n",
    "fig.add_subplot(rows, columns, 3)\n",
    "plt.imshow(gr3_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"st equation\")\n",
    "#method 4\n",
    "# weighted to lighten blue tones\n",
    "B, G, R = img[:, :, 0], img[:, :, 1], img[:, :, 2]\n",
    "gr4_img = 0.2989 * R + 0.587 * G + 0.0114 * B\n",
    "fig.add_subplot(rows, columns, 4)\n",
    "plt.imshow(gr4_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"weighted equation - blue lighter\")\n",
    "#cv2.imwrite(\"gray_weight.jpg\", gr4_img)\n",
    "#method 5\n",
    "# weighted to darken green tones + light blue tones\n",
    "B, G, R = img[:, :, 0], img[:, :, 1], img[:, :, 2]\n",
    "#gr_img = 0.0989 * R + 0.487 * G + 0.114 * B\n",
    "gr5_img = 0.0989 * R + 0.487 * G + 0.114 * B\n",
    "fig.add_subplot(rows, columns, 5)\n",
    "plt.imshow(gr5_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"weighted equation - green darker + blue lighter\")\n",
    "#method 6\n",
    "gr6_img = np.zeros(img.shape, img.dtype)\n",
    "gr6_img[:] = np.max(img,axis=-1,keepdims=1)/2 + np.min(img,axis=-1,keepdims=1)/2\n",
    "fig.add_subplot(rows, columns, 6)\n",
    "plt.imshow(gr6_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"lightness method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global brightness and contrast adjustment\n",
    "https://docs.opencv.org/3.4/d3/dc1/tutorial_basic_linear_transform.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from builtins import input\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "image = gray_img\n",
    "new_image = np.zeros(image.shape, image.dtype)\n",
    "alpha = 1.0 # Simple contrast control\n",
    "beta = 0    # Simple brightness control\n",
    "\n",
    "new_image = cv.convertScaleAbs(image, alpha=alpha, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure to display the resulting image\n",
    "fig = plt.figure(figsize=(20, 7))\n",
    "rows = 1\n",
    "columns = 2\n",
    "# Adds a subplot at the 1st position\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(gray_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"original\")\n",
    "# Adds a subplot at the 1st position\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(new_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"adjusted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear gradient : the part below runs, but it's too long to run (why ? the pixel by pixel grayscale conversion above goes fast...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from builtins import input\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "# Read image given by user\n",
    "#parser = argparse.ArgumentParser(description='Code for Changing the contrast and brightness of an image! tutorial.')\n",
    "#parser.add_argument('--input', help='Path to input image.', default='lena.jpg')\n",
    "#args = parser.parse_args()\n",
    "#image = cv.imread(cv.samples.findFile(args.input))\n",
    "image = orig_img\n",
    "if image is None:\n",
    "    print('Could not open or find the image: ', args.input)\n",
    "    exit(0)\n",
    "new_image = np.zeros(image.shape, image.dtype)\n",
    "\n",
    "# Initialize values\n",
    "print(' Basic Linear Transforms ')\n",
    "print('-------------------------')\n",
    "\n",
    "new_image = orig_img\n",
    "alpha = 1   #contrast\n",
    "beta = 70   #brightness\n",
    "img_len = image.shape[1]\n",
    "\n",
    "# Linear gradient to adjust brightness\n",
    "# Do the operation new_image(i,j) = alpha*image(i,j) + beta\n",
    "#accessing each pixel separately\n",
    "for y in range(image.shape[0]):\n",
    "    for x in range(0, image.shape[1]):\n",
    "        beta_x = beta - ((x+1)*beta/img_len)\n",
    "        new_image[y,x] = np.clip(alpha*image[y,x] + beta_x, 0, 255)\n",
    "#cv.imshow('Original Image', image)\n",
    "#cv.imshow('New Image', new_image)\n",
    "\n",
    "# create figure\n",
    "fig = plt.figure(figsize=(20, 7))\n",
    "rows = 1\n",
    "columns = 2\n",
    "# Adds a subplot at the 1st position\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(orig_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"original\")\n",
    "# Adds a subplot at the 1st position\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(new_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"adjusted\")\n",
    "\n",
    "# Wait until user press some key\n",
    "#cv.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not functioning, seems to be made for merging images\n",
    "contrast = 1\n",
    "brightness = 1\n",
    "out = cv2.addWeighted(gray_img, contrast, img, 0, brightness)\n",
    "output = cv2.addWeighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear gradient to balance brightness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the light field, might be useful to have a linear gradient instead/on top of the radial one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radial gradient to balance brightness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting brightness radially (due to led ring):\n",
    "https://www.geeksforgeeks.org/changing-the-contrast-and-brightness-of-an-image-using-python-opencv/\n",
    "https://happycoding.io/examples/processing/for-loops/radial-gradient (to draw gradients but same for exploring pixels)\n",
    "http://opensask.ca/Python/MoreAboutIteration/ImageProcessingWithSelection.html (process pix by pix in diff areas)\n",
    "https://www.geeksforgeeks.org/create-a-vignette-filter-using-python-opencv/ (for vignette -> to reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radial gradient to adjust brightness \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems to work but very slow, is there a way to optimize it ?\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "   \n",
    "     \n",
    "#reading the image\n",
    "input_image = cv2.imread('food.jpeg')\n",
    "   \n",
    "#resizing the image according to our need\n",
    "# resize() function takes 2 parameters, \n",
    "# the image and the dimensions\n",
    "input_image = cv2.resize(input_image, (480, 480))\n",
    "   \n",
    "# Extracting the height and width of an image\n",
    "rows, cols = input_image.shape[:2]\n",
    "   \n",
    "# generating vignette mask using Gaussian\n",
    "# resultant_kernels\n",
    "X_resultant_kernel = cv2.getGaussianKernel(cols,200)\n",
    "Y_resultant_kernel = cv2.getGaussianKernel(rows,200)\n",
    "   \n",
    "#generating resultant_kernel matrix\n",
    "resultant_kernel = Y_resultant_kernel * X_resultant_kernel.T\n",
    "   \n",
    "#creating mask and normalising by using np.linalg\n",
    "# function\n",
    "mask = 255 * resultant_kernel / np.linalg.norm(resultant_kernel)\n",
    "output = np.copy(input_image)\n",
    "   \n",
    "# applying the mask to each channel in the input image\n",
    "for i in range(3):\n",
    "    output[:,:,i] = output[:,:,i] * mask\n",
    "       \n",
    "#displaying the original image  \n",
    "cv2.imshow('Original', input_image)\n",
    "   \n",
    "#displaying the vignette filter image\n",
    "cv2.imshow('VIGNETTE', output)\n",
    "   \n",
    "# Maintain output window utill\n",
    "# user presses a key\n",
    "cv2.waitKey(0)\n",
    "   \n",
    "# Destroying present windows on screen\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contour - edge filters\n",
    "https://github.com/trucabrac/python_for_microscopists/blob/master/103_edge_filters.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw contour and bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "def getContours(im):\n",
    "  (hc, wc) = im.shape[:2]\n",
    "  x1 = wc/2\n",
    "  x2=wc/2\n",
    "  y1=hc/2\n",
    "  y2=hc/2\n",
    "  \n",
    "  contours,hierarchy = cv2.findContours(im, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "  for cnt in contours:\n",
    "    area= cv2.contourArea(cnt)\n",
    "    if area>0:\n",
    "      imgMid=cv2.drawContours(imgContour,cnt,-1,(0,255,0),6)\n",
    "      #peri = cv2.arcLength(cnt,True)\n",
    "      #approx = cv2.approxPolyDP(cnt,) \n",
    "    \n",
    "      #draw bounding rectangles\n",
    "      x,y,w,h = cv2.boundingRect(cnt)\n",
    "      #if x < x1: x1 = x-20\n",
    "      #if x+w > x2: x2 = x+w+20\n",
    "      #if y < y1: y1 = y-20\n",
    "      #if y+h > y2: y2 = y+h+20\n",
    "      if x < x1: x1 = x\n",
    "      if x+w > x2: x2 = x+w\n",
    "      if y < y1: y1 = y\n",
    "      if y+h > y2: y2 = y+h\n",
    "  imgFinal = cv2.rectangle(imgMid,(x1+50,y1+50),(x2-50,y2-50),(255,0,0),6)\n",
    "  #cv2.putText(imgFinal, word, (x1, y1-20), font, 2, (255,0,0), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Canny:\n",
    "The Process of Canny edge detection algorithm can be broken down to 5 different steps:\n",
    "1. Apply Gaussian filter to smooth the image in order to remove the noise\n",
    "2. Find the intensity gradients of the image\n",
    "3. Apply non-maximum suppression to get rid of spurious response to edge detection\n",
    "4. Apply double threshold to determine potential edges (supplied by the user)\n",
    "5. Track edge by hysteresis: Finalize the detection of edges by suppressing all the other edges that\n",
    "are weak and not connected to strong edges.\n",
    "\"\"\"\n",
    "#Autocanny\n",
    "sigma = 0.3\n",
    "median = np.median(adj_img)\n",
    "\n",
    "# apply automatic Canny edge detection using the computed median\n",
    "lower = int(max(0, (1.0 - sigma) * median))\n",
    "upper = int(min(255, (1.0 + sigma) * median))\n",
    "canny_img = cv2.Canny(adj_img, lower, upper)\n",
    "plt.imshow(canny_img, cmap='gray')\n",
    "cv2.imshow('VIGNETTE', canny_img)\n",
    "cv2.imwrite(\"canny.jpg\", canny_img)\n",
    "\n",
    "#cv2.imshow(\"Auto Canny\", auto_canny) #indeed much better than Canny directly applied\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw contours\n",
    "imgContour = cv2.cvtColor(adj_img, cv2.COLOR_GRAY2RGB)\n",
    "#imgContour = adj_img\n",
    "getContours(canny_img)\n",
    "plt.imshow(imgContour)\n",
    "cv2.imshow('VIGNETTE', imgContour)\n",
    "cv2.imwrite(\"cont.jpg\", imgContour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other methods for edge detection\n",
    "\n",
    "from skimage.filters import roberts, sobel, scharr, prewitt, farid\n",
    "roberts_img = roberts(gr_img)\n",
    "sobel_img = sobel(gr_img)\n",
    "scharr_img = scharr(gr_img)\n",
    "prewitt_img = prewitt(gr_img)\n",
    "farid_img = farid(gr_img)\n",
    "cv2.imshow(\"Roberts\", roberts_img)\n",
    "cv2.imshow(\"Sobel\", sobel_img)\n",
    "cv2.imshow(\"Scharr\", scharr_img)\n",
    "cv2.imshow(\"Prewitt\", prewitt_img)\n",
    "cv2.imshow(\"Farid\", farid_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "Can it run locally ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess img \n",
    "dim = (224, 224)\n",
    "sizImg = cv2.resize(img, dim, interpolation=cv2.INTER_LINEAR)\n",
    "#cv2_imshow(sizImg)\n",
    "x = cv2.cvtColor(sizImg, cv2.COLOR_GRAY2RGB)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "model_vgg16 = VGG16(weights='imagenet')\n",
    "preds = model_vgg16.predict(x)\n",
    "pred_top = decode_predictions(preds, top=20)[0]\n",
    "print('Predicted:', pred_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
