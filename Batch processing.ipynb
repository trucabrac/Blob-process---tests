{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/bnsreenu/python_for_microscopists/blob/master/182_batch_processing_multiple_images_in_python.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from skimage.filters import gaussian\n",
    "from skimage import img_as_ubyte\n",
    "import random\n",
    "from google.colab.patches import cv2_imshow\n",
    "import csv\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read images and store them in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to adapt depending on where the images are going to be stored\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/blob-tl/\n",
    "\n",
    "path = \"*.*\"\n",
    "#pathOut = \"test-clas/\"\n",
    "pathOut = \"../tl-contour/\" #folder to create beforehand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd tl-selec/tl10/\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#Capture all mages into an array and then iterate through each image\n",
    "#Normally used for machine learning workflows.\n",
    "\n",
    "images_list = []\n",
    "images_names = []\n",
    "\n",
    "#First create a stack array of all images\n",
    "for file in glob.glob(path):\n",
    "    print(file)     #just stop here to see all file names printed\n",
    "    img0= cv2.imread(file, 0)  #now, we can read each file since we have the full path\n",
    "    #img = cv2.cvtColor(imgIn, cv2.IMREAD_GRAYSCALE)\n",
    "    #img = cv2.resize(img, (SIZE, SIZE))\n",
    "    images_list.append(img0)\n",
    "    images_names.append(file)\n",
    "        \n",
    "images_list = np.array(images_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Image adjustments \n",
    "grayscale, brightness, contrast..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process each image in the array\n",
    "img_number = 0\n",
    "for image in range(images_list.shape[0]):\n",
    "    inImg = images_list[image,:,:]  #Grey images. For color add another dim.\n",
    "    \n",
    "    ########################################################\n",
    "    #IMAGE ADJUSTMENTS : grayscale, brightness/contrast, homogeneisation, crop...\n",
    "    \n",
    "    # convert from BGR to RGB\n",
    "    inImg = cv2.cvtColor(inImg, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # convert to GRAYSCALE\n",
    "    R, G, B = inImg[:, :, 0], img[:, :, 1], img[:, :, 2]\n",
    "    gr_img = 0.0989 * R + 0.487 * G + 0.114 * B\n",
    "    \n",
    "    # Global adjustment : brightness and contrast\n",
    "    alpha = 1.2   #contrast\n",
    "    beta = 20   #brightness\n",
    "    adj_img = cv2.convertScaleAbs(orig_img, alpha=alpha, beta=beta)\n",
    "    \n",
    "    # Extra adjustment  : radial gradient ? \n",
    "    #-> to see depending on new setup\n",
    "    \n",
    "    # crop ?\n",
    "    \n",
    "    # save the image at this step in 1 folder to have the nocontour-notclassified result\n",
    "    cv2.imwrite(pathOut+images_names[image], imgContour)\n",
    "    \n",
    "    \n",
    "    ########################################################\n",
    "    #CLASSIFICATION \n",
    "    # we use 3 pretrained Keras models : VGG16, ResNet50 and MobileNet (they all work with 224x224 images)\n",
    "    # for each image : 1 of these models is chosen randomly, \n",
    "    # then 1 of the 20 best predictions is also chosen randomly to add some variety to the results\n",
    "    # we store the info in a csv .doc (see later if it is useful)\n",
    "    \n",
    "    #preprocess img \n",
    "    dim = (224, 224)\n",
    "    sizImg = cv2.resize(inImg, dim, interpolation=cv2.INTER_LINEAR)\n",
    "    x = cv2.cvtColor(sizImg, cv2.COLOR_GRAY2RGB) # or use the original inImg \n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    #Classify with Keras models\n",
    "    #call randomly one of the models\n",
    "    nModel = random.randint(0,2)\n",
    "    if nModel==0:\n",
    "      model_vgg16 = VGG16(weights='imagenet')\n",
    "      preds = model_vgg16.predict(x)\n",
    "    if nModel==1:\n",
    "      model_rn50 = ResNet50(weights='imagenet')\n",
    "      preds = model_rn50.predict(x)\n",
    "    if nModel==2:\n",
    "      model_mobilenet = MobileNet(weights='imagenet')\n",
    "      preds = model_mobilenet.predict(x)\n",
    "    # decode the results into a list of tuples (class, description, probability)\n",
    "    # and choose 1 result randomly from the top20\n",
    "    pred_top = decode_predictions(preds, top=20)[0]\n",
    "    topn = random.randint(0,19)\n",
    "    pred_dis = pred_top[topn][1]\n",
    "    \n",
    "    # write img-ref + class + proba in csv ?\n",
    "    \n",
    "    ########################################################\n",
    "    #PROCESSING THE CLASSIFIED IMAGE\n",
    "    \n",
    "    #find contours and draw them\n",
    "    imgCanny = cv2.Canny(inImg,300,300) #parameters to adjust, it could work better\n",
    "    imgContour = cv2.cvtColor(inImg, cv2.COLOR_GRAY2RGB)\n",
    "    getContours2(imgCanny)\n",
    "    #cv2_imshow(imgContour)\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Contour detection, bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Saving the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
